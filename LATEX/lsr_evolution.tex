\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{graphicx}
\graphicspath{{../}}
\usepackage{xcolor}
\usepackage{float}
\usepackage{listings}

\lstset{
  basicstyle=\small\ttfamily,
  breaklines=true,
  frame=single,
  language=Python, % close enough for Julia highlighting
  keywordstyle=\color{blue},
  commentstyle=\color{gray},
  columns=flexible
}

\title{Evolution of the LSR Monte Carlo Simulation:\\
From Masking to CUDA Streams}
\author{}
\date{}

\begin{document}
\maketitle

\section{Overview}

This document describes the progression of four GPU-accelerated Monte Carlo
implementations for the LSR (Log-Sum-ReLU / Epanechnikov) energy function
in Dense Associative Memory on the $N$-sphere:
\begin{enumerate}
    \item \texttt{generate\_lsr\_longeq\_gpu.jl} --- the \emph{masking} version (v1),
    \item \texttt{generate\_lsr\_longeq\_gpu\_v2.jl} --- the \emph{T-loop} version (v2),
    \item \texttt{generate\_lsr\_longeq\_gpu\_v3.jl} --- the \emph{heating protocol} version (v3),
    \item \texttt{generate\_lsr\_longeq\_gpu\_v4.jl} --- the \emph{CUDA streams + fine grid} version (v4).
\end{enumerate}
All three share the same physics (LSR energy with $b = 2 + \sqrt{2} \approx 3.414$),
the same Metropolis--Hastings algorithm on $S^{N-1}(\sqrt{N})$, and the same
adaptive-$N$ scheme ($N(\alpha) = \lfloor \ln P / \alpha \rceil$).
They differ in how the temperature dimension is handled during equilibration,
which turns out to be the decisive factor for the accuracy of the phase diagram.

\section{The Shared LSR Energy and MC Kernel}

All three versions compute the LSR energy via batched CUBLAS matrix--vector products:
\begin{equation}
    H_{\mathrm{LSR}}(\mathbf{x}) = -\frac{N}{b}\ln\sum_{\mu=1}^{P}
    \max\!\Bigl(0,\; 1 - b + \frac{b}{N}\,\boldsymbol{\xi}^\mu\!\cdot\mathbf{x}\Bigr).
\end{equation}
When the state $\mathbf{x}$ lies outside the support of \emph{all} patterns
(i.e.\ the argument of every $\max$ is zero), the energy is set to
$E_{\infty} = 10^{30}$, effectively creating an impenetrable barrier.
The Metropolis proposal is a Gaussian perturbation projected back onto the sphere:
\begin{equation}
    \mathbf{x}' = \sqrt{N}\,\frac{\mathbf{x} + \delta\,\boldsymbol{\eta}}
    {\|\mathbf{x} + \delta\,\boldsymbol{\eta}\|},
    \qquad \boldsymbol{\eta} \sim \mathcal{N}(0, I_N),
    \qquad \delta = \max(0.1,\; 2.4/\sqrt{N}).
\end{equation}

\section{Version 1: Masking Approach}

\subsection{Architecture}

Version~1 processes \emph{all temperatures simultaneously} by packing the $T$
dimension into the state arrays.  For each $\alpha_i$, the state tensor has shape
$[N_i \times n_T \times N_{\mathrm{trials}}]$, and the inverse temperature
$\beta = 1/T$ is stored as a GPU vector of length $n_T \times N_{\mathrm{trials}}$.

The T-dependent equilibration is implemented via a \emph{masking} mechanism:
\begin{enumerate}
    \item Run all $n_T$ temperature chains in parallel.
    \item Maintain a boolean mask \texttt{active}$[1, n_T, N_{\mathrm{trials}}]$.
    \item Advance the simulation step by step.  When a temperature $T_j$ has
    accumulated its allotted $N_{\mathrm{eq}}(T_j)$ steps, deactivate it in the mask.
    \item Use \texttt{mc\_step\_masked!}, which skips accept/reject for inactive chains.
    \item Continue until the coldest temperature (requiring the most steps) finishes.
\end{enumerate}

\subsection{Key functions}

\begin{itemize}
    \item \texttt{compute\_energy\_lsr!}: batched energy via
    \texttt{gemm\_strided\_batched} over $[N, n_T, N_{\mathrm{trials}}]$ arrays.
    \item \texttt{mc\_step\_masked!}: Metropolis step that only updates chains
    where \texttt{active} is true.
    \item \texttt{mc\_step!}: standard (unmasked) Metropolis step used during
    sampling.
\end{itemize}

\subsection{Initialization}

All $({\alpha}, T)$ chains are initialized independently near the target pattern:
\begin{equation}
    \mathbf{x}^{(i,j)}_0 = \sqrt{N_i}\,
    \frac{\boldsymbol{\xi}^1_i + 0.05\,\boldsymbol{\eta}}
    {\|\boldsymbol{\xi}^1_i + 0.05\,\boldsymbol{\eta}\|},
    \qquad \forall\; i \in [n_\alpha],\; j \in [n_T].
\end{equation}

\subsection{Limitations}

\begin{itemize}
    \item \textbf{Wasted compute}: after a high-$T$ chain reaches its equilibration
    quota and is masked out, the GPU still processes the entire $[N, n_T, N_{\mathrm{trials}}]$
    tensor.  Inactive chains consume memory bandwidth without doing useful work.
    \item \textbf{Complexity}: the threshold-based deactivation logic (sorting unique
    $N_{\mathrm{eq}}$ values, updating masks, transferring to GPU) adds code complexity
    and potential for bugs.
    \item \textbf{Metastability}: every temperature is initialized near the target,
    so the ``blue bay'' artifact is present.
\end{itemize}


\section{Version 2: T-Loop Approach}

\subsection{Motivation}

Version~2 eliminates the masking overhead by processing each temperature
\emph{sequentially} in a dedicated loop.  Each $T_j$ receives exactly
$N_{\mathrm{eq}}(T_j)$ equilibration steps with no wasted compute on deactivated
chains.

\subsection{Architecture}

The state storage changes from a 3D tensor to a nested array:
\[
    \texttt{xs\_full}[i][j] \in \mathbb{R}^{N_i \times 1 \times N_{\mathrm{trials}}},
    \qquad i \in [n_\alpha],\; j \in [n_T].
\]
Each $({\alpha}, T)$ pair has its own independent GPU array.  The inverse temperature
$\beta$ is now a \emph{scalar} (not a vector), and the MC step function
\texttt{mc\_step\_single\_T!} takes $\beta$ as a scalar argument.

\subsection{Equilibration}

The equilibration loop processes temperatures from cold to hot:
\begin{lstlisting}
for j in 1:n_T
    beta = 1 / T_vec[j]
    n_eq = N_EQ_vec[j]    # T-dependent
    for step in 1:n_eq
        for i in 1:n_alpha
            mc_step_single_T!(xs_full[i][j], ..., beta, ...)
        end
    end
end
\end{lstlisting}
The sampling phase is separate and iterates over all $({\alpha}, T)$ pairs.

\subsection{Improvements over v1}

\begin{itemize}
    \item \textbf{No wasted compute}: each $T$ runs for exactly $N_{\mathrm{eq}}(T_j)$
    steps, with no idle chains.
    \item \textbf{Simpler code}: no masking logic, no threshold management.
    \item \textbf{Scalar $\beta$}: enables \texttt{gemm\_strided\_batched} on
    $[N, 1, N_{\mathrm{trials}}]$ arrays, which is more cache-friendly for
    moderate $N$.
\end{itemize}

\subsection{Persistent limitation: independent initialization}

Despite the structural improvements, v2 retains the same initialization strategy
as v1: every \texttt{xs\_full}$[i][j]$ is initialized independently near the
target pattern.  There is \textbf{no data flow between different temperatures}
during equilibration.  Each $({\alpha}, T)$ simulation is an isolated MC run that
must independently escape the retrieval basin if the equilibrium state is
disordered.  This leads to the ``blue bay'' artifact described in
Section~\ref{sec:blue_bay}.


\section{The Blue Bay Artifact}
\label{sec:blue_bay}

\subsection{Observation}

The phase diagram produced by v2 (right panel of \texttt{maps1\_longeq.png})
exhibits a prominent region of high $\varphi$ (blue) extending \emph{above}
the theoretical phase boundary $\alpha_c(T)$, particularly at
$\alpha \approx 0.25$--$0.35$ and $T \approx 0.3$--$1.5$.  We call this the
``blue bay.''

\subsection{Physical mechanism}

The theoretical boundary marks where the retrieval free energy
$f_{\mathrm{ret}} = u(\phi) - T\,s(\phi, q)$ equals the noise-floor energy
$u_{\mathrm{noise}}$ (a first-order phase transition).  Above the boundary,
the spin-glass state has lower free energy, but the retrieval state persists
as a \emph{metastable local minimum} separated from the spin-glass by a
free-energy barrier.

For the LSR kernel, this barrier is especially severe:
\begin{enumerate}
    \item The ReLU support creates \textbf{hard walls}: any MC proposal that
    moves the state outside all pattern supports encounters $E = 10^{30}$
    and is always rejected.
    \item Near the support threshold
    $\alpha_{\mathrm{th}} = \tfrac{1}{2}(1 - 1/b)^2 \approx 0.25$,
    very few spurious patterns contribute to the noise floor, so the barrier
    between retrieval and spin-glass is tall relative to the driving force.
    \item The MC chain, initialized near the target, cannot escape within
    the allotted equilibration time.
\end{enumerate}

\subsection{Why LSE does not exhibit this artifact}

The companion LSE simulation (\texttt{generate\_lse\_longeq\_gpu.jl}) uses
the same initialization strategy but produces a clean phase diagram.
Two factors explain this:
\begin{itemize}
    \item The Gaussian kernel has \emph{infinite} tails --- there are no hard
    energy walls, so the MC chain can smoothly diffuse away from the target at
    high~$T$.
    \item The LSE simulation uses stronger statistics: $N_{\mathrm{trials}} = 256$
    (vs.\ 64), $N_{\mathrm{samp}} = 5{,}000$ (vs.\ 500), and a flat
    $N_{\mathrm{eq}} = 50{,}000$ (vs.\ $\sim\!5{,}000$ at high~$T$).
\end{itemize}


\section{Version 3: Heating Protocol}

\subsection{Core idea}

Instead of initializing each temperature independently, v3 \emph{propagates}
the equilibrated state from $T_j$ to $T_{j+1}$:
\begin{enumerate}
    \item At the coldest temperature $T_1 = 0.05$, initialize near the target
    and equilibrate heavily ($N_{\mathrm{eq}}^{\mathrm{init}} = 20{,}000$ steps).
    This is correct: at low~$T$ the retrieval state is the true equilibrium.
    \item For each subsequent $T_{j+1} = T_j + \Delta T$, \emph{keep} the state
    from $T_j$ and re-equilibrate with $N_{\mathrm{eq}}^{\mathrm{step}} = 5{,}000$
    steps at the new temperature.
    \item As $T$ increases past $T_c$, thermal fluctuations naturally
    destabilize the retrieval basin.  Because the state is already equilibrated at
    $T_j \lesssim T_c$, the small perturbation $\Delta T = 0.05$ is sufficient to
    push the system over the weakening barrier.
\end{enumerate}

\subsection{Architecture}

The state storage simplifies to a single array per $\alpha$:
\[
    \texttt{xs\_g}[i] \in \mathbb{R}^{N_i \times 1 \times N_{\mathrm{trials}}},
    \qquad i \in [n_\alpha].
\]
This array is \emph{reused} across all temperatures---after equilibrating and
sampling at $T_j$, the same array (carrying the final state) enters the
equilibration loop for $T_{j+1}$.

The equilibration and sampling phases are \emph{merged} into a single
temperature loop:
\begin{lstlisting}
for j in 1:n_T
    beta = 1 / T_vec[j]
    n_eq = (j == 1) ? N_EQ_INIT : N_EQ_STEP

    # Equilibrate (state carries from T_{j-1})
    for step in 1:n_eq
        for i in 1:n_alpha
            mc_step_single_T!(xs_g[i], ..., beta, ...)
        end
    end

    # Sample
    for step in 1:N_SAMP
        for i in 1:n_alpha
            mc_step_single_T!(xs_g[i], ..., beta, ...)
            phi_acc[i] += overlap(xs_g[i], target[i])
        end
    end

    phi_grid[:, j] = mean(phi_acc) / N_SAMP
    # xs_g carries forward to T_{j+1}
end
\end{lstlisting}

\subsection{Why the LSR energy is compatible with heating}

A key technical point: the LSR energy function does not depend on temperature.
Temperature enters only through the Metropolis acceptance criterion
$\min(1, e^{-\beta\,\Delta E})$.  Therefore, the stored energies
$E_i$ remain valid when $\beta$ changes between temperature steps, and no
energy recomputation is needed at the start of each $T_j$.


\section{Version 4: CUDA Streams + Fine Grid}

\subsection{Motivation}

While v3 successfully eliminates the blue bay, the inner loop over $\alpha$
values is fully sequential: each MC step issues $n_\alpha$ small CUBLAS calls
one after another.  For the v3 grid ($n_\alpha = 18$, $N \sim 8$--$20$,
$N_{\mathrm{trials}} = 256$), each \texttt{gemm\_strided\_batched} operates on
very small matrices, severely underutilizing an A6000's 10{,}752 CUDA cores.
To afford a finer grid (55~$\alpha$ values, 50~$T$ points), the per-step
time must be reduced.

\subsection{CUDA streams for concurrent $\alpha$ processing}

Version~4 creates one CUDA stream per $\alpha$ value and dispatches the
compute kernel for each $\alpha_i$ to its own stream.  The GPU scheduler can
then overlap the small kernels from different streams, filling otherwise
idle SMs:
\begin{lstlisting}
streams = [CuStream() for _ in 1:n_alpha]

for i in 1:n_alpha
    CUDA.stream!(streams[i]) do
        mc_step_prerand!(xs_g[i], xp_cur[i], ...,
                         ra_cur[i], ...)
    end
end
CUDA.synchronize()
\end{lstlisting}

All operations inside the \texttt{stream!} block---CUBLAS, broadcast kernels,
reductions---are submitted to the specified stream.  The GPU executes them
concurrently across streams when resources are available.

\subsection{Separating random generation from compute}

A key constraint prevents simply wrapping the original
\texttt{mc\_step\_single\_T!} in a stream block: CUDA's cuRAND generator
maintains internal state that is \textbf{not safe} for concurrent access from
multiple streams.  Calling \texttt{CUDA.randn!} on different streams from the
same generator would corrupt the RNG state.

Version~4 therefore introduces \texttt{mc\_step\_prerand!}, which expects
\emph{pre-filled} random arrays:
\begin{itemize}
    \item \texttt{xp}: pre-filled with $\mathcal{N}(0,1)$ noise (overwritten
    in-place with the proposal).
    \item \texttt{ra}: pre-filled with $\mathrm{U}(0,1)$ values for accept/reject.
\end{itemize}
All random number generation happens on the default stream (sequential, safe),
while the deterministic compute is dispatched to per-$\alpha$ streams.

\subsection{Double-buffered RNG}

To overlap random generation with compute, v4 maintains two sets of random
buffers (A and B).  Within each MC step:
\begin{enumerate}
    \item Dispatch compute using the \emph{current} buffer to per-$\alpha$ streams.
    \item Generate next step's random numbers into the \emph{alternate} buffer on
    the default stream.
    \item \texttt{CUDA.synchronize()} --- wait for both compute and random
    generation.
    \item Swap buffer pointers.
\end{enumerate}

\begin{lstlisting}
xp_cur, xp_nxt = xp_A, xp_B
ra_cur, ra_nxt = ra_A, ra_B

# Pre-fill first buffer
fill_randoms!(xp_cur, ra_cur, n_alpha)
CUDA.synchronize()

for step in 1:n_eq
    # Compute on current buffer (per-alpha streams)
    dispatch_eq_step!(streams, xs_g, xp_cur, ...)

    # Generate next randoms (default stream, alternate buffer)
    fill_randoms!(xp_nxt, ra_nxt, n_alpha)

    CUDA.synchronize()  # one sync per MC step
    xp_cur, xp_nxt = xp_nxt, xp_cur
    ra_cur, ra_nxt = ra_nxt, ra_cur
end
\end{lstlisting}

Because compute uses buffer~A while random generation fills buffer~B (or vice
versa), there are no write--write conflicts, and only a single
\texttt{CUDA.synchronize()} is needed per MC step.

\subsection{Finer grids}

With better GPU utilization from streams, v4 uses substantially finer grids:
\begin{itemize}
    \item $\alpha = 0.01, 0.02, \ldots, 0.55$ (55 values, vs.\ 18 in v3).
    \item $T$: 50 log-spaced points from $10^{-2}$ to $2.5$ (vs.\ 20 in v3).
\end{itemize}
The log-spaced temperature grid from v3 is preserved, providing dense sampling
near the phase transition at low~$T$ and coarser sampling at high~$T$ where the
order parameter is featureless.

The extended $\alpha$ range (down to 0.01) includes the regime
$\alpha < \alpha_{\mathrm{th}} \approx 0.043$ where the support threshold
guarantees perfect retrieval at any temperature, providing an internal
consistency check.

\subsection{Memory considerations}

For low $\alpha$ values (e.g.\ $\alpha = 0.01$), the adaptive-$N$ scheme
gives $N = \lceil \ln P / \alpha \rceil \approx 621$, with $P = 50$.
The pattern array $[N \times P \times N_{\mathrm{trials}}]$ for this single
$\alpha$ occupies $\sim\!4$~MB (with $N_{\mathrm{trials}} = 32$).  The total
GPU memory across all 55~$\alpha$ values is dominated by the high-$N$, low-$P$
values and is well within A6000 capacity.

The double-buffered proposal and uniform arrays add only
$2 \times \sum_i (N_i \times N_{\mathrm{trials}} + N_{\mathrm{trials}})
\times 4$~bytes $\approx 20$~MB of overhead.


\section{Summary of Differences}

\begin{table}[H]
\centering
\small
\begin{tabular}{lcccc}
\toprule
& \textbf{v1 (Masking)} & \textbf{v2 (T-loop)} & \textbf{v3 (Heating)} & \textbf{v4 (Streams)} \\
\midrule
State shape per $\alpha$
  & $[N, n_T, N_{\mathrm{tr}}]$
  & $[N, 1, N_{\mathrm{tr}}] \!\times\! n_T$
  & $[N, 1, N_{\mathrm{tr}}] \!\times\! 1$
  & $[N, 1, N_{\mathrm{tr}}] \!\times\! 1$ \\[2pt]
$\beta$ type
  & GPU vector
  & scalar
  & scalar
  & scalar \\[2pt]
MC step function
  & \texttt{mc\_step\_masked!}
  & \texttt{mc\_step\_single\_T!}
  & \texttt{mc\_step\_single\_T!}
  & \texttt{mc\_step\_prerand!} \\[2pt]
$\alpha$ parallelism
  & sequential
  & sequential
  & sequential
  & CUDA streams \\[2pt]
RNG strategy
  & inline
  & inline
  & inline
  & double-buffered \\[2pt]
Equilibration
  & masking
  & independent per $T$
  & sequential heating
  & sequential heating \\[2pt]
$N_{\mathrm{eq}}$ schedule
  & $5\text{k} \times e^{0.15/T}$
  & same
  & flat init + step
  & flat init + step \\[2pt]
Initialization
  & all $(\alpha,T)$ near target
  & all $(\alpha,T)$ near target
  & only $T_1$ near target
  & only $T_1$ near target \\[2pt]
Data flow between $T$
  & none
  & none
  & $T_j \!\to\! T_{j+1}$
  & $T_j \!\to\! T_{j+1}$ \\[2pt]
GPU arrays for states
  & $n_\alpha$ (batched)
  & $n_\alpha \!\times\! n_T$
  & $n_\alpha$
  & $n_\alpha$ \\[2pt]
\midrule
$n_\alpha \times n_T$
  & $18 \times 30$
  & $18 \times 30$
  & $18 \times 20$
  & $55 \times 50$ \\[2pt]
$T$ grid
  & linear
  & linear
  & log-spaced
  & log-spaced \\[2pt]
Output file
  & \texttt{lsr\_longeq.csv}
  & \texttt{lsr\_longeq.csv}
  & \texttt{lsr\_heating.csv}
  & \texttt{lsr\_heating.csv} \\
\bottomrule
\end{tabular}
\caption{Comparison of the four LSR Monte Carlo implementations.}
\label{tab:comparison}
\end{table}


\section{Expected Impact on the Phase Diagram}

The heating protocol (v3/v4) is designed to eliminate the blue bay by ensuring
that the MC chain has a physically continuous thermal history:
\begin{itemize}
    \item At $T < T_c$: the system is in retrieval (correct).  The state from
    $T_{j-1}$ is a good starting point, and re-equilibration steps are
    sufficient for the small perturbation in log-spaced $T$.
    \item At $T \approx T_c$: the free-energy barrier between retrieval and
    spin-glass is weakening.  Because the system is already equilibrated at
    $T_{j-1} \lesssim T_c$, the barrier crossing requires only a modest
    thermal push.
    \item At $T > T_c$: the system has already transitioned to spin-glass at
    $T \approx T_c$.  Subsequent heating steps maintain the disordered state.
\end{itemize}

There is a known caveat: because this is a heating protocol, the observed
transition temperature may be slightly \emph{above} the thermodynamic $T_c$
(superheating effect at a first-order transition).  The magnitude of this
shift depends on the barrier height relative to the temperature step size and
the number of re-equilibration steps.  For the moderate system sizes in this
simulation ($N \sim 2$--$620$), the superheating shift is expected to be small.

Version~4's finer grids and CUDA-stream parallelism provide the sharpest
phase diagram to date, with the extended $\alpha$ range capturing both the
support-threshold regime ($\alpha < \alpha_{\mathrm{th}}$) and the full
phase boundary up to $\alpha = 0.55$.

\end{document}
